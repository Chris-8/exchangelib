<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.3" />
<title>exchangelib.queryset API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>exchangelib.queryset</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from copy import deepcopy
from itertools import islice
import logging

from .errors import MultipleObjectsReturned, DoesNotExist
from .items import CalendarItem, ID_ONLY
from .fields import FieldPath, FieldOrder
from .properties import InvalidField
from .restriction import Q
from .services import CHUNK_SIZE
from .version import EXCHANGE_2010

log = logging.getLogger(__name__)


class SearchableMixIn:
    &#34;&#34;&#34;Implements a search API for inheritance&#34;&#34;&#34;

    def get(self, *args, **kwargs):
        raise NotImplementedError()

    def all(self):
        raise NotImplementedError()

    def none(self):
        raise NotImplementedError()

    def filter(self, *args, **kwargs):
        raise NotImplementedError()

    def exclude(self, *args, **kwargs):
        raise NotImplementedError()

    def people(self):
        raise NotImplementedError()


class QuerySet(SearchableMixIn):
    &#34;&#34;&#34;A Django QuerySet-like class for querying items. Defers queries until the QuerySet is consumed. Supports chaining to
    build up complex queries.

    Django QuerySet documentation: https://docs.djangoproject.com/en/dev/ref/models/querysets/

    &#34;&#34;&#34;
    VALUES = &#39;values&#39;
    VALUES_LIST = &#39;values_list&#39;
    FLAT = &#39;flat&#39;
    NONE = &#39;none&#39;
    RETURN_TYPES = (VALUES, VALUES_LIST, FLAT, NONE)

    ITEM = &#39;item&#39;
    PERSONA = &#39;persona&#39;
    REQUEST_TYPES = (ITEM, PERSONA)

    def __init__(self, folder_collection, request_type=ITEM):
        from .folders import FolderCollection
        if not isinstance(folder_collection, FolderCollection):
            raise ValueError(&#34;folder_collection value &#39;%s&#39; must be a FolderCollection instance&#34; % folder_collection)
        self.folder_collection = folder_collection  # A FolderCollection instance
        if request_type not in self.REQUEST_TYPES:
            raise ValueError(&#34;&#39;request_type&#39; %r must be one of %s&#34; % (request_type, self.REQUEST_TYPES))
        self.request_type = request_type
        self.q = Q()  # Default to no restrictions
        self.only_fields = None
        self.order_fields = None
        self.return_format = self.NONE
        self.calendar_view = None
        self.page_size = None
        self.max_items = None
        self.offset = 0
        self._depth = None

        self._cache = None

    def _copy_self(self):
        # When we copy a queryset where the cache has already been filled, we don&#39;t copy the cache. Thus, a copied
        # queryset will fetch results from the server again.
        #
        # All other behaviour would be awkward:
        #
        # qs = QuerySet(f).filter(foo=&#39;bar&#39;)
        # items = list(qs)
        # new_qs = qs.exclude(bar=&#39;baz&#39;)  # This should work, and should fetch from the server
        #
        if not isinstance(self.q, Q):
            raise ValueError(&#34;self.q value &#39;%s&#39; must be None or a Q instance&#34; % self.q)
        if not isinstance(self.only_fields, (type(None), tuple)):
            raise ValueError(&#34;self.only_fields value &#39;%s&#39; must be None or a tuple&#34; % self.only_fields)
        if not isinstance(self.order_fields, (type(None), tuple)):
            raise ValueError(&#34;self.order_fields value &#39;%s&#39; must be None or a tuple&#34; % self.order_fields)
        if self.return_format not in self.RETURN_TYPES:
            raise ValueError(&#34;self.return_value &#39;%s&#39; must be one of %s&#34; % (self.return_format, self.RETURN_TYPES))
        # Only mutable objects need to be deepcopied. Folder should be the same object
        new_qs = self.__class__(self.folder_collection, request_type=self.request_type)
        new_qs.q = deepcopy(self.q)
        new_qs.only_fields = self.only_fields
        new_qs.order_fields = None if self.order_fields is None else deepcopy(self.order_fields)
        new_qs.return_format = self.return_format
        new_qs.calendar_view = self.calendar_view
        new_qs.page_size = self.page_size
        new_qs.max_items = self.max_items
        new_qs.offset = self.offset
        new_qs._depth = self._depth
        return new_qs

    @property
    def is_cached(self):
        return self._cache is not None

    def _get_field_path(self, field_path):
        from .items import Persona
        if self.request_type == self.PERSONA:
            return FieldPath(field=Persona.get_field_by_fieldname(field_path))
        for folder in self.folder_collection:
            try:
                return FieldPath.from_string(field_path=field_path, folder=folder)
            except InvalidField:
                pass
        raise InvalidField(&#34;Unknown field path %r on folders %s&#34; % (field_path, self.folder_collection.folders))

    def _get_field_order(self, field_path):
        from .items import Persona
        if self.request_type == self.PERSONA:
            return FieldOrder(
                field_path=FieldPath(field=Persona.get_field_by_fieldname(field_path.lstrip(&#39;-&#39;))),
                reverse=field_path.startswith(&#39;-&#39;),
            )
        for folder in self.folder_collection:
            try:
                return FieldOrder.from_string(field_path=field_path, folder=folder)
            except InvalidField:
                pass
        raise InvalidField(&#34;Unknown field path %r on folders %s&#34; % (field_path, self.folder_collection.folders))

    @property
    def _id_field(self):
        return self._get_field_path(&#39;id&#39;)

    @property
    def _changekey_field(self):
        return self._get_field_path(&#39;changekey&#39;)

    def _additional_fields(self):
        if not isinstance(self.only_fields, tuple):
            raise ValueError(&#34;&#39;only_fields&#39; value %r must be a tuple&#34; % self.only_fields)
        # Remove ItemId and ChangeKey. We get them unconditionally
        additional_fields = {f for f in self.only_fields if not f.field.is_attribute}
        if self.request_type != self.ITEM:
            return additional_fields

        # For CalendarItem items, we want to inject internal timezone fields into the requested fields.
        has_start = &#39;start&#39; in {f.field.name for f in additional_fields}
        has_end = &#39;end&#39; in {f.field.name for f in additional_fields}
        meeting_tz_field, start_tz_field, end_tz_field = CalendarItem.timezone_fields()
        if self.folder_collection.account.version.build &lt; EXCHANGE_2010:
            if has_start or has_end:
                additional_fields.add(FieldPath(field=meeting_tz_field))
        else:
            if has_start:
                additional_fields.add(FieldPath(field=start_tz_field))
            if has_end:
                additional_fields.add(FieldPath(field=end_tz_field))
        return additional_fields

    def _format_items(self, items, return_format):
        return {
            self.VALUES: self._as_values,
            self.VALUES_LIST: self._as_values_list,
            self.FLAT: self._as_flat_values_list,
            self.NONE: self._as_items,
        }[return_format](items)

    def _query(self):
        from .items import Persona
        if self.only_fields is None:
            # We didn&#39;t restrict list of field paths. Get all fields from the server, including extended properties.
            if self.request_type == self.PERSONA:
                additional_fields = {FieldPath(field=f) for f in Persona.supported_fields(
                    version=self.folder_collection.account.version
                ) if not f.is_complex}
                complex_fields_requested = False
            else:
                additional_fields = {FieldPath(field=f) for f in self.folder_collection.allowed_item_fields()}
                complex_fields_requested = True
        else:
            additional_fields = self._additional_fields()
            complex_fields_requested = any(f.field.is_complex for f in additional_fields)

        # EWS can do server-side sorting on multiple fields. A caveat is that server-side sorting is not supported
        # for calendar views. In this case, we do all the sorting client-side.
        if self.calendar_view:
            must_sort_clientside = bool(self.order_fields)
            order_fields = None
        else:
            must_sort_clientside = False
            order_fields = self.order_fields

        if must_sort_clientside:
            # Also fetch order_by fields that we only need for client-side sorting.
            extra_order_fields = {f.field_path for f in self.order_fields} - additional_fields
            if extra_order_fields:
                additional_fields.update(extra_order_fields)
        else:
            extra_order_fields = set()

        if self.request_type == self.PERSONA:
            if len(self.folder_collection) != 1:
                raise ValueError(&#39;Personas can only be queried on a single folder&#39;)
            items = list(self.folder_collection)[0].find_people(
                self.q,
                shape=ID_ONLY,
                depth=self._depth,
                additional_fields=additional_fields,
                order_fields=order_fields,
                page_size=self.page_size,
                max_items=self.max_items,
                offset=self.offset,
            )
        else:
            find_item_kwargs = dict(
                shape=ID_ONLY,  # Always use IdOnly here, because AllProperties doesn&#39;t actually get *all* properties
                depth=self._depth,
                additional_fields=additional_fields,
                order_fields=order_fields,
                calendar_view=self.calendar_view,
                page_size=self.page_size,
                max_items=self.max_items,
                offset=self.offset,
            )

            if complex_fields_requested:
                # The FindItem service does not support complex field types. Tell find_items() to return
                # (id, changekey) tuples, and pass that to fetch().
                find_item_kwargs[&#39;additional_fields&#39;] = None
                items = self.folder_collection.account.fetch(
                    ids=self.folder_collection.find_items(self.q, **find_item_kwargs),
                    only_fields=additional_fields,
                    chunk_size=self.page_size,
                )
            else:
                if not additional_fields:
                    # If additional_fields is the empty set, we only requested ID and changekey fields. We can then
                    # take a shortcut by using (shape=ID_ONLY, additional_fields=None) to tell find_items() to return
                    # (id, changekey) tuples. We&#39;ll post-process those later.
                    find_item_kwargs[&#39;additional_fields&#39;] = None
                items = self.folder_collection.find_items(self.q, **find_item_kwargs)

        if not must_sort_clientside:
            return items

        # Resort to client-side sorting of the order_by fields. This is greedy. Sorting in Python is stable, so when
        # sorting on multiple fields, we can just do a sort on each of the requested fields in reverse order. Reverse
        # each sort operation if the field was marked as such.
        for f in reversed(self.order_fields):
            try:
                items = sorted(items, key=lambda i: _get_value_or_default(i, f), reverse=f.reverse)
            except TypeError as e:
                if &#39;unorderable types&#39; not in e.args[0]:
                    raise
                raise ValueError((
                    &#34;Cannot sort on field &#39;%s&#39;. The field has no default value defined, and there are either items &#34;
                    &#34;with None values for this field, or the query contains exception instances (original error: %s).&#34;)
                                 % (f.field_path, e))
        if not extra_order_fields:
            return items

        # Nullify the fields we only needed for sorting before returning
        return (_rinse_item(i, extra_order_fields) for i in items)

    def __iter__(self):
        # Fill cache if this is the first iteration. Return an iterator over the results. Make this non-greedy by
        # filling the cache while we are iterating.
        #
        # We don&#39;t set self._cache until the iterator is finished. Otherwise an interrupted iterator would leave the
        # cache in an inconsistent state.
        if self.is_cached:
            for val in self._cache:
                yield val
            return

        if self.q.is_never():
            self._cache = []
            return

        log.debug(&#39;Initializing cache&#39;)
        _cache = []
        for val in self._format_items(items=self._query(), return_format=self.return_format):
            _cache.append(val)
            yield val
        self._cache = _cache

    &#34;&#34;&#34;Do not implement __len__. The implementation of list() tries to preallocate memory by calling __len__ on the
    given sequence, before calling __iter__. If we implemented __len__, we would end up calling FindItems twice, once
    to get the result of self.count(), an once to return the actual result.

    Also, according to https://stackoverflow.com/questions/37189968/how-to-have-list-consume-iter-without-calling-len,
    a __len__ implementation should be cheap. That does not hold for self.count().

    def __len__(self):
        if self.is_cached:
            return len(self._cache)
        # This queryset has no cache yet. Call the optimized counting implementation
        return self.count()
    &#34;&#34;&#34;

    def __getitem__(self, idx_or_slice):
        # Support indexing and slicing. This is non-greedy when possible (slicing start, stop and step are not negative,
        # and we&#39;re ordering on at most one field), and will only fill the cache if the entire query is iterated.
        if isinstance(idx_or_slice, int):
            return self._getitem_idx(idx_or_slice)
        return self._getitem_slice(idx_or_slice)

    def _getitem_idx(self, idx):
        if self.is_cached:
            return self._cache[idx]
        if idx &lt; 0:
            # Support negative indexes by reversing the queryset and negating the index value
            reverse_idx = -(idx+1)
            return self.reverse()[reverse_idx]
        # Optimize by setting an exact offset and fetching only 1 item
        new_qs = self._copy_self()
        new_qs.max_items = 1
        new_qs.page_size = 1
        new_qs.offset = idx
        # The iterator will return at most 1 item
        for item in new_qs.__iter__():
            return item
        raise IndexError()

    def _getitem_slice(self, s):
        if ((s.start or 0) &lt; 0) or ((s.stop or 0) &lt; 0) or ((s.step or 0) &lt; 0):
            # islice() does not support negative start, stop and step. Make sure cache is full by iterating the full
            # query result, and then slice on the cache.
            list(self.__iter__())
            return self._cache[s]
        if self.is_cached:
            return islice(self.__iter__(), s.start, s.stop, s.step)
        # Optimize by setting an exact offset and max_items value
        new_qs = self._copy_self()
        if s.start is not None and s.stop is not None:
            new_qs.offset = s.start
            new_qs.max_items = s.stop - s.start
        elif s.start is not None:
            new_qs.offset = s.start
        elif s.stop is not None:
            new_qs.max_items = s.stop
        if new_qs.page_size is None and new_qs.max_items is not None and new_qs.max_items &lt; CHUNK_SIZE:
            new_qs.page_size = new_qs.max_items
        return islice(new_qs.__iter__(), None, None, s.step)

    def _item_yielder(self, iterable, item_func, id_only_func, changekey_only_func, id_and_changekey_func):
        # Transforms results from the server according to the given transform functions. Makes sure to pass on
        # Exception instances unaltered.
        if self.only_fields:
            has_non_attribute_fields = bool({f for f in self.only_fields if not f.field.is_attribute})
        else:
            has_non_attribute_fields = True
        if not has_non_attribute_fields:
            # _query() will return an iterator of (id, changekey) tuples
            if self._changekey_field not in self.only_fields:
                transform_func = id_only_func
            elif self._id_field not in self.only_fields:
                transform_func = changekey_only_func
            else:
                transform_func = id_and_changekey_func
            for i in iterable:
                if isinstance(i, Exception):
                    yield i
                    continue
                yield transform_func(*i)
            return
        for i in iterable:
            if isinstance(i, Exception):
                yield i
                continue
            yield item_func(i)

    def _as_items(self, iterable):
        from .items import Item
        return self._item_yielder(
            iterable=iterable,
            item_func=lambda i: i,
            id_only_func=lambda item_id, changekey: Item(id=item_id),
            changekey_only_func=lambda item_id, changekey: Item(changekey=changekey),
            id_and_changekey_func=lambda item_id, changekey: Item(id=item_id, changekey=changekey),
        )

    def _as_values(self, iterable):
        if not self.only_fields:
            raise ValueError(&#39;values() requires at least one field name&#39;)
        return self._item_yielder(
            iterable=iterable,
            item_func=lambda i: {f.path: f.get_value(i) for f in self.only_fields},
            id_only_func=lambda item_id, changekey: {&#39;id&#39;: item_id},
            changekey_only_func=lambda item_id, changekey: {&#39;changekey&#39;: changekey},
            id_and_changekey_func=lambda item_id, changekey: {&#39;id&#39;: item_id, &#39;changekey&#39;: changekey},
        )

    def _as_values_list(self, iterable):
        if not self.only_fields:
            raise ValueError(&#39;values_list() requires at least one field name&#39;)
        return self._item_yielder(
            iterable=iterable,
            item_func=lambda i: tuple(f.get_value(i) for f in self.only_fields),
            id_only_func=lambda item_id, changekey: (item_id,),
            changekey_only_func=lambda item_id, changekey: (changekey,),
            id_and_changekey_func=lambda item_id, changekey: (item_id, changekey),
        )

    def _as_flat_values_list(self, iterable):
        if not self.only_fields or len(self.only_fields) != 1:
            raise ValueError(&#39;flat=True requires exactly one field name&#39;)
        flat_field_path = self.only_fields[0]
        return self._item_yielder(
            iterable=iterable,
            item_func=flat_field_path.get_value,
            id_only_func=lambda item_id, changekey: item_id,
            changekey_only_func=lambda item_id, changekey: changekey,
            id_and_changekey_func=None,  # Can never be called
        )

    ###############################
    #
    # Methods that support chaining
    #
    ###############################
    # Return copies of self, so this works as expected:
    #
    # foo_qs = my_folder.filter(...)
    # foo_qs.filter(foo=&#39;bar&#39;)
    # foo_qs.filter(foo=&#39;baz&#39;)  # Should not be affected by the previous statement
    #
    def all(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        new_qs = self._copy_self()
        return new_qs

    def none(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        new_qs = self._copy_self()
        new_qs.q = Q(conn_type=Q.NEVER)
        return new_qs

    def filter(self, *args, **kwargs):
        &#34;&#34;&#34;

        Args:
          *args:
          **kwargs:


        &#34;&#34;&#34;
        new_qs = self._copy_self()
        q = Q(*args, **kwargs)
        new_qs.q = new_qs.q &amp; q
        return new_qs

    def exclude(self, *args, **kwargs):
        &#34;&#34;&#34;

        Args:
          *args:
          **kwargs:


        &#34;&#34;&#34;
        new_qs = self._copy_self()
        q = ~Q(*args, **kwargs)
        new_qs.q = new_qs.q &amp; q
        return new_qs

    def people(self):
        &#34;&#34;&#34;Changes the queryset to search the folder for Personas instead of Items&#34;&#34;&#34;
        new_qs = self._copy_self()
        new_qs.request_type = self.PERSONA
        return new_qs

    def only(self, *args):
        &#34;&#34;&#34;Fetch only the specified field names. All other item fields will be &#39;None&#39;

        Args:
          *args:

        &#34;&#34;&#34;
        try:
            only_fields = tuple(self._get_field_path(arg) for arg in args)
        except ValueError as e:
            raise ValueError(&#34;%s in only()&#34; % e.args[0])
        new_qs = self._copy_self()
        new_qs.only_fields = only_fields
        return new_qs

    def order_by(self, *args):
        &#34;&#34;&#34;

        Args:
          *args:

        Returns:
          in reverse order. EWS only supports server-side sorting on a single field. Sorting on multiple fields is
          implemented client-side and will therefore make the query greedy

        &#34;&#34;&#34;
        try:
            order_fields = tuple(self._get_field_order(arg) for arg in args)
        except ValueError as e:
            raise ValueError(&#34;%s in order_by()&#34; % e.args[0])
        new_qs = self._copy_self()
        new_qs.order_fields = order_fields
        return new_qs

    def reverse(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        if not self.order_fields:
            raise ValueError(&#39;Reversing only makes sense if there are order_by fields&#39;)
        new_qs = self._copy_self()
        for f in new_qs.order_fields:
            f.reverse = not f.reverse
        return new_qs

    def values(self, *args):
        &#34;&#34;&#34;

        Args:
          *args:


        &#34;&#34;&#34;
        try:
            only_fields = tuple(self._get_field_path(arg) for arg in args)
        except ValueError as e:
            raise ValueError(&#34;%s in values()&#34; % e.args[0])
        new_qs = self._copy_self()
        new_qs.only_fields = only_fields
        new_qs.return_format = self.VALUES
        return new_qs

    def values_list(self, *args, **kwargs):
        &#34;&#34;&#34;Return the values of the specified field names as lists. If called with flat=True and only one field name,

        Args:
          *args:
          **kwargs:

        Returns:
          Allow an arbitrary list of fields in *args, possibly ending with flat=True|False

        &#34;&#34;&#34;
        flat = kwargs.pop(&#39;flat&#39;, False)
        if kwargs:
            raise AttributeError(&#39;Unknown kwargs: %s&#39; % kwargs)
        if flat and len(args) != 1:
            raise ValueError(&#39;flat=True requires exactly one field name&#39;)
        try:
            only_fields = tuple(self._get_field_path(arg) for arg in args)
        except ValueError as e:
            raise ValueError(&#34;%s in values_list()&#34; % e.args[0])
        new_qs = self._copy_self()
        new_qs.only_fields = only_fields
        new_qs.return_format = self.FLAT if flat else self.VALUES_LIST
        return new_qs

    def depth(self, depth):
        &#34;&#34;&#34;Specify the search depth (SHALLOW, ASSOCIATED or DEEP)

        Args:
          depth:

        &#34;&#34;&#34;
        new_qs = self._copy_self()
        new_qs._depth = depth
        return new_qs

    ###########################
    #
    # Methods that end chaining
    #
    ###########################

    def iterator(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        if self.q.is_never():
            return []
        if self.is_cached:
            return self._cache
        # Return an iterator that doesn&#39;t bother with caching
        return self._format_items(items=self._query(), return_format=self.return_format)

    def get(self, *args, **kwargs):
        &#34;&#34;&#34;Assume the query will return exactly one item. Return that item

        Args:
          *args:
          **kwargs:

        &#34;&#34;&#34;
        if self.is_cached and not args and not kwargs:
            # We can only safely use the cache if get() is called without args
            items = self._cache
        elif not args and set(kwargs.keys()) in ({&#39;id&#39;}, {&#39;id&#39;, &#39;changekey&#39;}):
            # We allow calling get(id=..., changekey=...) to get a single item, but only if exactly these two
            # kwargs are present.
            account = self.folder_collection.account
            item_id = self._id_field.field.clean(kwargs[&#39;id&#39;], version=account.version)
            changekey = self._changekey_field.field.clean(kwargs.get(&#39;changekey&#39;), version=account.version)
            items = list(account.fetch(ids=[(item_id, changekey)], only_fields=self.only_fields))
        else:
            new_qs = self.filter(*args, **kwargs)
            items = list(new_qs.__iter__())
        if not items:
            raise DoesNotExist()
        if len(items) != 1:
            raise MultipleObjectsReturned()
        return items[0]

    def count(self, page_size=1000):
        &#34;&#34;&#34;Get the query count, with as little effort as possible &#39;page_size&#39; is the number of items to
        fetch from the server per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          page_size:  (Default value = 1000)

        &#34;&#34;&#34;
        if self.is_cached:
            return len(self._cache)
        new_qs = self._copy_self()
        new_qs.only_fields = tuple()
        new_qs.order_fields = None
        new_qs.return_format = self.NONE
        new_qs.page_size = page_size
        return len(list(new_qs.__iter__()))

    def exists(self):
        &#34;&#34;&#34;Find out if the query contains any hits, with as little effort as possible&#34;&#34;&#34;
        if self.is_cached:
            return len(self._cache) &gt; 0
        new_qs = self._copy_self()
        new_qs.max_items = 1
        return new_qs.count(page_size=1) &gt; 0

    def _id_only_copy_self(self):
        new_qs = self._copy_self()
        new_qs.only_fields = tuple()
        new_qs.order_fields = None
        new_qs.return_format = self.NONE
        return new_qs

    def delete(self, page_size=1000, **delete_kwargs):
        &#34;&#34;&#34;Delete the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and delete per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          page_size:  (Default value = 1000)
          **delete_kwargs:

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_delete(
            ids=ids,
            chunk_size=page_size,
            **delete_kwargs
        )
        self._cache = None  # Invalidate the cache, regardless of the results
        return res

    def send(self, page_size=1000, **send_kwargs):
        &#34;&#34;&#34;Send the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and send per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          page_size:  (Default value = 1000)
          **send_kwargs:

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_send(
            ids=ids,
            chunk_size=page_size,
            **send_kwargs
        )
        self._cache = None  # Invalidate the cache, regardless of the results
        return res

    def copy(self, to_folder, page_size=1000, **copy_kwargs):
        &#34;&#34;&#34;Copy the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and copy per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          to_folder:
          page_size:  (Default value = 1000)
          **copy_kwargs:

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_copy(
            ids=ids,
            to_folder=to_folder,
            chunk_size=page_size,
            **copy_kwargs
        )
        self._cache = None  # Invalidate the cache, regardless of the results
        return res

    def move(self, to_folder, page_size=1000):
        &#34;&#34;&#34;Move the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and move per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          to_folder:
          page_size:  (Default value = 1000)

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_move(
            ids=ids,
            to_folder=to_folder,
            chunk_size=page_size,
        )
        self._cache = None  # Invalidate the cache after delete, regardless of the results
        return res

    def archive(self, to_folder, page_size=1000):
        &#34;&#34;&#34;Archive the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and move per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          to_folder:
          page_size:  (Default value = 1000)

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_archive(
            ids=ids,
            to_folder=to_folder,
            chunk_size=page_size,
        )
        self._cache = None  # Invalidate the cache after delete, regardless of the results
        return res

    def __str__(self):
        fmt_args = [(&#39;q&#39;, str(self.q)), (&#39;folders&#39;, &#39;[%s]&#39; % &#39;, &#39;.join(str(f) for f in self.folder_collection.folders))]
        if self.is_cached:
            fmt_args.append((&#39;len&#39;, str(len(self._cache))))
        return self.__class__.__name__ + &#39;(%s)&#39; % &#39;, &#39;.join(&#39;%s=%s&#39; % (k, v) for k, v in fmt_args)


def _get_value_or_default(item, field_order):
    # Python can only sort values when &lt;, &gt; and = are implemented for the two types. Try as best we can to sort
    # items, even when the item may have a None value for the field in question, or when the item is an
    # Exception. In that case, we calculate a default value and sort all None values and exceptions as the default
    # value.
    if isinstance(item, Exception):
        return _default_field_value(field_order.field_path.field)
    val = field_order.field_path.get_value(item)
    if val is None:
        return _default_field_value(field_order.field_path.field)
    return val


def _default_field_value(field):
    # Returns the default value of a field. If the field does not have a default value, try creating an empty instance
    # of the field value class. If that doesn&#39;t work, there&#39;s really nothing we can do about it; we&#39;ll raise an error.
    return field.default or field.value_cls()


def _rinse_item(i, fields_to_nullify):
    # Set fields in fields_to_nullify to None. Make sure to accept exceptions.
    if isinstance(i, Exception):
        return i
    for f in fields_to_nullify:
        setattr(i, f.field.name, None)
    return i</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="exchangelib.queryset.QuerySet"><code class="flex name class">
<span>class <span class="ident">QuerySet</span></span>
<span>(</span><span>folder_collection, request_type='item')</span>
</code></dt>
<dd>
<div class="desc"><p>A Django QuerySet-like class for querying items. Defers queries until the QuerySet is consumed. Supports chaining to
build up complex queries.</p>
<p>Django QuerySet documentation: <a href="https://docs.djangoproject.com/en/dev/ref/models/querysets/">https://docs.djangoproject.com/en/dev/ref/models/querysets/</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class QuerySet(SearchableMixIn):
    &#34;&#34;&#34;A Django QuerySet-like class for querying items. Defers queries until the QuerySet is consumed. Supports chaining to
    build up complex queries.

    Django QuerySet documentation: https://docs.djangoproject.com/en/dev/ref/models/querysets/

    &#34;&#34;&#34;
    VALUES = &#39;values&#39;
    VALUES_LIST = &#39;values_list&#39;
    FLAT = &#39;flat&#39;
    NONE = &#39;none&#39;
    RETURN_TYPES = (VALUES, VALUES_LIST, FLAT, NONE)

    ITEM = &#39;item&#39;
    PERSONA = &#39;persona&#39;
    REQUEST_TYPES = (ITEM, PERSONA)

    def __init__(self, folder_collection, request_type=ITEM):
        from .folders import FolderCollection
        if not isinstance(folder_collection, FolderCollection):
            raise ValueError(&#34;folder_collection value &#39;%s&#39; must be a FolderCollection instance&#34; % folder_collection)
        self.folder_collection = folder_collection  # A FolderCollection instance
        if request_type not in self.REQUEST_TYPES:
            raise ValueError(&#34;&#39;request_type&#39; %r must be one of %s&#34; % (request_type, self.REQUEST_TYPES))
        self.request_type = request_type
        self.q = Q()  # Default to no restrictions
        self.only_fields = None
        self.order_fields = None
        self.return_format = self.NONE
        self.calendar_view = None
        self.page_size = None
        self.max_items = None
        self.offset = 0
        self._depth = None

        self._cache = None

    def _copy_self(self):
        # When we copy a queryset where the cache has already been filled, we don&#39;t copy the cache. Thus, a copied
        # queryset will fetch results from the server again.
        #
        # All other behaviour would be awkward:
        #
        # qs = QuerySet(f).filter(foo=&#39;bar&#39;)
        # items = list(qs)
        # new_qs = qs.exclude(bar=&#39;baz&#39;)  # This should work, and should fetch from the server
        #
        if not isinstance(self.q, Q):
            raise ValueError(&#34;self.q value &#39;%s&#39; must be None or a Q instance&#34; % self.q)
        if not isinstance(self.only_fields, (type(None), tuple)):
            raise ValueError(&#34;self.only_fields value &#39;%s&#39; must be None or a tuple&#34; % self.only_fields)
        if not isinstance(self.order_fields, (type(None), tuple)):
            raise ValueError(&#34;self.order_fields value &#39;%s&#39; must be None or a tuple&#34; % self.order_fields)
        if self.return_format not in self.RETURN_TYPES:
            raise ValueError(&#34;self.return_value &#39;%s&#39; must be one of %s&#34; % (self.return_format, self.RETURN_TYPES))
        # Only mutable objects need to be deepcopied. Folder should be the same object
        new_qs = self.__class__(self.folder_collection, request_type=self.request_type)
        new_qs.q = deepcopy(self.q)
        new_qs.only_fields = self.only_fields
        new_qs.order_fields = None if self.order_fields is None else deepcopy(self.order_fields)
        new_qs.return_format = self.return_format
        new_qs.calendar_view = self.calendar_view
        new_qs.page_size = self.page_size
        new_qs.max_items = self.max_items
        new_qs.offset = self.offset
        new_qs._depth = self._depth
        return new_qs

    @property
    def is_cached(self):
        return self._cache is not None

    def _get_field_path(self, field_path):
        from .items import Persona
        if self.request_type == self.PERSONA:
            return FieldPath(field=Persona.get_field_by_fieldname(field_path))
        for folder in self.folder_collection:
            try:
                return FieldPath.from_string(field_path=field_path, folder=folder)
            except InvalidField:
                pass
        raise InvalidField(&#34;Unknown field path %r on folders %s&#34; % (field_path, self.folder_collection.folders))

    def _get_field_order(self, field_path):
        from .items import Persona
        if self.request_type == self.PERSONA:
            return FieldOrder(
                field_path=FieldPath(field=Persona.get_field_by_fieldname(field_path.lstrip(&#39;-&#39;))),
                reverse=field_path.startswith(&#39;-&#39;),
            )
        for folder in self.folder_collection:
            try:
                return FieldOrder.from_string(field_path=field_path, folder=folder)
            except InvalidField:
                pass
        raise InvalidField(&#34;Unknown field path %r on folders %s&#34; % (field_path, self.folder_collection.folders))

    @property
    def _id_field(self):
        return self._get_field_path(&#39;id&#39;)

    @property
    def _changekey_field(self):
        return self._get_field_path(&#39;changekey&#39;)

    def _additional_fields(self):
        if not isinstance(self.only_fields, tuple):
            raise ValueError(&#34;&#39;only_fields&#39; value %r must be a tuple&#34; % self.only_fields)
        # Remove ItemId and ChangeKey. We get them unconditionally
        additional_fields = {f for f in self.only_fields if not f.field.is_attribute}
        if self.request_type != self.ITEM:
            return additional_fields

        # For CalendarItem items, we want to inject internal timezone fields into the requested fields.
        has_start = &#39;start&#39; in {f.field.name for f in additional_fields}
        has_end = &#39;end&#39; in {f.field.name for f in additional_fields}
        meeting_tz_field, start_tz_field, end_tz_field = CalendarItem.timezone_fields()
        if self.folder_collection.account.version.build &lt; EXCHANGE_2010:
            if has_start or has_end:
                additional_fields.add(FieldPath(field=meeting_tz_field))
        else:
            if has_start:
                additional_fields.add(FieldPath(field=start_tz_field))
            if has_end:
                additional_fields.add(FieldPath(field=end_tz_field))
        return additional_fields

    def _format_items(self, items, return_format):
        return {
            self.VALUES: self._as_values,
            self.VALUES_LIST: self._as_values_list,
            self.FLAT: self._as_flat_values_list,
            self.NONE: self._as_items,
        }[return_format](items)

    def _query(self):
        from .items import Persona
        if self.only_fields is None:
            # We didn&#39;t restrict list of field paths. Get all fields from the server, including extended properties.
            if self.request_type == self.PERSONA:
                additional_fields = {FieldPath(field=f) for f in Persona.supported_fields(
                    version=self.folder_collection.account.version
                ) if not f.is_complex}
                complex_fields_requested = False
            else:
                additional_fields = {FieldPath(field=f) for f in self.folder_collection.allowed_item_fields()}
                complex_fields_requested = True
        else:
            additional_fields = self._additional_fields()
            complex_fields_requested = any(f.field.is_complex for f in additional_fields)

        # EWS can do server-side sorting on multiple fields. A caveat is that server-side sorting is not supported
        # for calendar views. In this case, we do all the sorting client-side.
        if self.calendar_view:
            must_sort_clientside = bool(self.order_fields)
            order_fields = None
        else:
            must_sort_clientside = False
            order_fields = self.order_fields

        if must_sort_clientside:
            # Also fetch order_by fields that we only need for client-side sorting.
            extra_order_fields = {f.field_path for f in self.order_fields} - additional_fields
            if extra_order_fields:
                additional_fields.update(extra_order_fields)
        else:
            extra_order_fields = set()

        if self.request_type == self.PERSONA:
            if len(self.folder_collection) != 1:
                raise ValueError(&#39;Personas can only be queried on a single folder&#39;)
            items = list(self.folder_collection)[0].find_people(
                self.q,
                shape=ID_ONLY,
                depth=self._depth,
                additional_fields=additional_fields,
                order_fields=order_fields,
                page_size=self.page_size,
                max_items=self.max_items,
                offset=self.offset,
            )
        else:
            find_item_kwargs = dict(
                shape=ID_ONLY,  # Always use IdOnly here, because AllProperties doesn&#39;t actually get *all* properties
                depth=self._depth,
                additional_fields=additional_fields,
                order_fields=order_fields,
                calendar_view=self.calendar_view,
                page_size=self.page_size,
                max_items=self.max_items,
                offset=self.offset,
            )

            if complex_fields_requested:
                # The FindItem service does not support complex field types. Tell find_items() to return
                # (id, changekey) tuples, and pass that to fetch().
                find_item_kwargs[&#39;additional_fields&#39;] = None
                items = self.folder_collection.account.fetch(
                    ids=self.folder_collection.find_items(self.q, **find_item_kwargs),
                    only_fields=additional_fields,
                    chunk_size=self.page_size,
                )
            else:
                if not additional_fields:
                    # If additional_fields is the empty set, we only requested ID and changekey fields. We can then
                    # take a shortcut by using (shape=ID_ONLY, additional_fields=None) to tell find_items() to return
                    # (id, changekey) tuples. We&#39;ll post-process those later.
                    find_item_kwargs[&#39;additional_fields&#39;] = None
                items = self.folder_collection.find_items(self.q, **find_item_kwargs)

        if not must_sort_clientside:
            return items

        # Resort to client-side sorting of the order_by fields. This is greedy. Sorting in Python is stable, so when
        # sorting on multiple fields, we can just do a sort on each of the requested fields in reverse order. Reverse
        # each sort operation if the field was marked as such.
        for f in reversed(self.order_fields):
            try:
                items = sorted(items, key=lambda i: _get_value_or_default(i, f), reverse=f.reverse)
            except TypeError as e:
                if &#39;unorderable types&#39; not in e.args[0]:
                    raise
                raise ValueError((
                    &#34;Cannot sort on field &#39;%s&#39;. The field has no default value defined, and there are either items &#34;
                    &#34;with None values for this field, or the query contains exception instances (original error: %s).&#34;)
                                 % (f.field_path, e))
        if not extra_order_fields:
            return items

        # Nullify the fields we only needed for sorting before returning
        return (_rinse_item(i, extra_order_fields) for i in items)

    def __iter__(self):
        # Fill cache if this is the first iteration. Return an iterator over the results. Make this non-greedy by
        # filling the cache while we are iterating.
        #
        # We don&#39;t set self._cache until the iterator is finished. Otherwise an interrupted iterator would leave the
        # cache in an inconsistent state.
        if self.is_cached:
            for val in self._cache:
                yield val
            return

        if self.q.is_never():
            self._cache = []
            return

        log.debug(&#39;Initializing cache&#39;)
        _cache = []
        for val in self._format_items(items=self._query(), return_format=self.return_format):
            _cache.append(val)
            yield val
        self._cache = _cache

    &#34;&#34;&#34;Do not implement __len__. The implementation of list() tries to preallocate memory by calling __len__ on the
    given sequence, before calling __iter__. If we implemented __len__, we would end up calling FindItems twice, once
    to get the result of self.count(), an once to return the actual result.

    Also, according to https://stackoverflow.com/questions/37189968/how-to-have-list-consume-iter-without-calling-len,
    a __len__ implementation should be cheap. That does not hold for self.count().

    def __len__(self):
        if self.is_cached:
            return len(self._cache)
        # This queryset has no cache yet. Call the optimized counting implementation
        return self.count()
    &#34;&#34;&#34;

    def __getitem__(self, idx_or_slice):
        # Support indexing and slicing. This is non-greedy when possible (slicing start, stop and step are not negative,
        # and we&#39;re ordering on at most one field), and will only fill the cache if the entire query is iterated.
        if isinstance(idx_or_slice, int):
            return self._getitem_idx(idx_or_slice)
        return self._getitem_slice(idx_or_slice)

    def _getitem_idx(self, idx):
        if self.is_cached:
            return self._cache[idx]
        if idx &lt; 0:
            # Support negative indexes by reversing the queryset and negating the index value
            reverse_idx = -(idx+1)
            return self.reverse()[reverse_idx]
        # Optimize by setting an exact offset and fetching only 1 item
        new_qs = self._copy_self()
        new_qs.max_items = 1
        new_qs.page_size = 1
        new_qs.offset = idx
        # The iterator will return at most 1 item
        for item in new_qs.__iter__():
            return item
        raise IndexError()

    def _getitem_slice(self, s):
        if ((s.start or 0) &lt; 0) or ((s.stop or 0) &lt; 0) or ((s.step or 0) &lt; 0):
            # islice() does not support negative start, stop and step. Make sure cache is full by iterating the full
            # query result, and then slice on the cache.
            list(self.__iter__())
            return self._cache[s]
        if self.is_cached:
            return islice(self.__iter__(), s.start, s.stop, s.step)
        # Optimize by setting an exact offset and max_items value
        new_qs = self._copy_self()
        if s.start is not None and s.stop is not None:
            new_qs.offset = s.start
            new_qs.max_items = s.stop - s.start
        elif s.start is not None:
            new_qs.offset = s.start
        elif s.stop is not None:
            new_qs.max_items = s.stop
        if new_qs.page_size is None and new_qs.max_items is not None and new_qs.max_items &lt; CHUNK_SIZE:
            new_qs.page_size = new_qs.max_items
        return islice(new_qs.__iter__(), None, None, s.step)

    def _item_yielder(self, iterable, item_func, id_only_func, changekey_only_func, id_and_changekey_func):
        # Transforms results from the server according to the given transform functions. Makes sure to pass on
        # Exception instances unaltered.
        if self.only_fields:
            has_non_attribute_fields = bool({f for f in self.only_fields if not f.field.is_attribute})
        else:
            has_non_attribute_fields = True
        if not has_non_attribute_fields:
            # _query() will return an iterator of (id, changekey) tuples
            if self._changekey_field not in self.only_fields:
                transform_func = id_only_func
            elif self._id_field not in self.only_fields:
                transform_func = changekey_only_func
            else:
                transform_func = id_and_changekey_func
            for i in iterable:
                if isinstance(i, Exception):
                    yield i
                    continue
                yield transform_func(*i)
            return
        for i in iterable:
            if isinstance(i, Exception):
                yield i
                continue
            yield item_func(i)

    def _as_items(self, iterable):
        from .items import Item
        return self._item_yielder(
            iterable=iterable,
            item_func=lambda i: i,
            id_only_func=lambda item_id, changekey: Item(id=item_id),
            changekey_only_func=lambda item_id, changekey: Item(changekey=changekey),
            id_and_changekey_func=lambda item_id, changekey: Item(id=item_id, changekey=changekey),
        )

    def _as_values(self, iterable):
        if not self.only_fields:
            raise ValueError(&#39;values() requires at least one field name&#39;)
        return self._item_yielder(
            iterable=iterable,
            item_func=lambda i: {f.path: f.get_value(i) for f in self.only_fields},
            id_only_func=lambda item_id, changekey: {&#39;id&#39;: item_id},
            changekey_only_func=lambda item_id, changekey: {&#39;changekey&#39;: changekey},
            id_and_changekey_func=lambda item_id, changekey: {&#39;id&#39;: item_id, &#39;changekey&#39;: changekey},
        )

    def _as_values_list(self, iterable):
        if not self.only_fields:
            raise ValueError(&#39;values_list() requires at least one field name&#39;)
        return self._item_yielder(
            iterable=iterable,
            item_func=lambda i: tuple(f.get_value(i) for f in self.only_fields),
            id_only_func=lambda item_id, changekey: (item_id,),
            changekey_only_func=lambda item_id, changekey: (changekey,),
            id_and_changekey_func=lambda item_id, changekey: (item_id, changekey),
        )

    def _as_flat_values_list(self, iterable):
        if not self.only_fields or len(self.only_fields) != 1:
            raise ValueError(&#39;flat=True requires exactly one field name&#39;)
        flat_field_path = self.only_fields[0]
        return self._item_yielder(
            iterable=iterable,
            item_func=flat_field_path.get_value,
            id_only_func=lambda item_id, changekey: item_id,
            changekey_only_func=lambda item_id, changekey: changekey,
            id_and_changekey_func=None,  # Can never be called
        )

    ###############################
    #
    # Methods that support chaining
    #
    ###############################
    # Return copies of self, so this works as expected:
    #
    # foo_qs = my_folder.filter(...)
    # foo_qs.filter(foo=&#39;bar&#39;)
    # foo_qs.filter(foo=&#39;baz&#39;)  # Should not be affected by the previous statement
    #
    def all(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        new_qs = self._copy_self()
        return new_qs

    def none(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        new_qs = self._copy_self()
        new_qs.q = Q(conn_type=Q.NEVER)
        return new_qs

    def filter(self, *args, **kwargs):
        &#34;&#34;&#34;

        Args:
          *args:
          **kwargs:


        &#34;&#34;&#34;
        new_qs = self._copy_self()
        q = Q(*args, **kwargs)
        new_qs.q = new_qs.q &amp; q
        return new_qs

    def exclude(self, *args, **kwargs):
        &#34;&#34;&#34;

        Args:
          *args:
          **kwargs:


        &#34;&#34;&#34;
        new_qs = self._copy_self()
        q = ~Q(*args, **kwargs)
        new_qs.q = new_qs.q &amp; q
        return new_qs

    def people(self):
        &#34;&#34;&#34;Changes the queryset to search the folder for Personas instead of Items&#34;&#34;&#34;
        new_qs = self._copy_self()
        new_qs.request_type = self.PERSONA
        return new_qs

    def only(self, *args):
        &#34;&#34;&#34;Fetch only the specified field names. All other item fields will be &#39;None&#39;

        Args:
          *args:

        &#34;&#34;&#34;
        try:
            only_fields = tuple(self._get_field_path(arg) for arg in args)
        except ValueError as e:
            raise ValueError(&#34;%s in only()&#34; % e.args[0])
        new_qs = self._copy_self()
        new_qs.only_fields = only_fields
        return new_qs

    def order_by(self, *args):
        &#34;&#34;&#34;

        Args:
          *args:

        Returns:
          in reverse order. EWS only supports server-side sorting on a single field. Sorting on multiple fields is
          implemented client-side and will therefore make the query greedy

        &#34;&#34;&#34;
        try:
            order_fields = tuple(self._get_field_order(arg) for arg in args)
        except ValueError as e:
            raise ValueError(&#34;%s in order_by()&#34; % e.args[0])
        new_qs = self._copy_self()
        new_qs.order_fields = order_fields
        return new_qs

    def reverse(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        if not self.order_fields:
            raise ValueError(&#39;Reversing only makes sense if there are order_by fields&#39;)
        new_qs = self._copy_self()
        for f in new_qs.order_fields:
            f.reverse = not f.reverse
        return new_qs

    def values(self, *args):
        &#34;&#34;&#34;

        Args:
          *args:


        &#34;&#34;&#34;
        try:
            only_fields = tuple(self._get_field_path(arg) for arg in args)
        except ValueError as e:
            raise ValueError(&#34;%s in values()&#34; % e.args[0])
        new_qs = self._copy_self()
        new_qs.only_fields = only_fields
        new_qs.return_format = self.VALUES
        return new_qs

    def values_list(self, *args, **kwargs):
        &#34;&#34;&#34;Return the values of the specified field names as lists. If called with flat=True and only one field name,

        Args:
          *args:
          **kwargs:

        Returns:
          Allow an arbitrary list of fields in *args, possibly ending with flat=True|False

        &#34;&#34;&#34;
        flat = kwargs.pop(&#39;flat&#39;, False)
        if kwargs:
            raise AttributeError(&#39;Unknown kwargs: %s&#39; % kwargs)
        if flat and len(args) != 1:
            raise ValueError(&#39;flat=True requires exactly one field name&#39;)
        try:
            only_fields = tuple(self._get_field_path(arg) for arg in args)
        except ValueError as e:
            raise ValueError(&#34;%s in values_list()&#34; % e.args[0])
        new_qs = self._copy_self()
        new_qs.only_fields = only_fields
        new_qs.return_format = self.FLAT if flat else self.VALUES_LIST
        return new_qs

    def depth(self, depth):
        &#34;&#34;&#34;Specify the search depth (SHALLOW, ASSOCIATED or DEEP)

        Args:
          depth:

        &#34;&#34;&#34;
        new_qs = self._copy_self()
        new_qs._depth = depth
        return new_qs

    ###########################
    #
    # Methods that end chaining
    #
    ###########################

    def iterator(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        if self.q.is_never():
            return []
        if self.is_cached:
            return self._cache
        # Return an iterator that doesn&#39;t bother with caching
        return self._format_items(items=self._query(), return_format=self.return_format)

    def get(self, *args, **kwargs):
        &#34;&#34;&#34;Assume the query will return exactly one item. Return that item

        Args:
          *args:
          **kwargs:

        &#34;&#34;&#34;
        if self.is_cached and not args and not kwargs:
            # We can only safely use the cache if get() is called without args
            items = self._cache
        elif not args and set(kwargs.keys()) in ({&#39;id&#39;}, {&#39;id&#39;, &#39;changekey&#39;}):
            # We allow calling get(id=..., changekey=...) to get a single item, but only if exactly these two
            # kwargs are present.
            account = self.folder_collection.account
            item_id = self._id_field.field.clean(kwargs[&#39;id&#39;], version=account.version)
            changekey = self._changekey_field.field.clean(kwargs.get(&#39;changekey&#39;), version=account.version)
            items = list(account.fetch(ids=[(item_id, changekey)], only_fields=self.only_fields))
        else:
            new_qs = self.filter(*args, **kwargs)
            items = list(new_qs.__iter__())
        if not items:
            raise DoesNotExist()
        if len(items) != 1:
            raise MultipleObjectsReturned()
        return items[0]

    def count(self, page_size=1000):
        &#34;&#34;&#34;Get the query count, with as little effort as possible &#39;page_size&#39; is the number of items to
        fetch from the server per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          page_size:  (Default value = 1000)

        &#34;&#34;&#34;
        if self.is_cached:
            return len(self._cache)
        new_qs = self._copy_self()
        new_qs.only_fields = tuple()
        new_qs.order_fields = None
        new_qs.return_format = self.NONE
        new_qs.page_size = page_size
        return len(list(new_qs.__iter__()))

    def exists(self):
        &#34;&#34;&#34;Find out if the query contains any hits, with as little effort as possible&#34;&#34;&#34;
        if self.is_cached:
            return len(self._cache) &gt; 0
        new_qs = self._copy_self()
        new_qs.max_items = 1
        return new_qs.count(page_size=1) &gt; 0

    def _id_only_copy_self(self):
        new_qs = self._copy_self()
        new_qs.only_fields = tuple()
        new_qs.order_fields = None
        new_qs.return_format = self.NONE
        return new_qs

    def delete(self, page_size=1000, **delete_kwargs):
        &#34;&#34;&#34;Delete the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and delete per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          page_size:  (Default value = 1000)
          **delete_kwargs:

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_delete(
            ids=ids,
            chunk_size=page_size,
            **delete_kwargs
        )
        self._cache = None  # Invalidate the cache, regardless of the results
        return res

    def send(self, page_size=1000, **send_kwargs):
        &#34;&#34;&#34;Send the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and send per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          page_size:  (Default value = 1000)
          **send_kwargs:

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_send(
            ids=ids,
            chunk_size=page_size,
            **send_kwargs
        )
        self._cache = None  # Invalidate the cache, regardless of the results
        return res

    def copy(self, to_folder, page_size=1000, **copy_kwargs):
        &#34;&#34;&#34;Copy the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and copy per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          to_folder:
          page_size:  (Default value = 1000)
          **copy_kwargs:

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_copy(
            ids=ids,
            to_folder=to_folder,
            chunk_size=page_size,
            **copy_kwargs
        )
        self._cache = None  # Invalidate the cache, regardless of the results
        return res

    def move(self, to_folder, page_size=1000):
        &#34;&#34;&#34;Move the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and move per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          to_folder:
          page_size:  (Default value = 1000)

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_move(
            ids=ids,
            to_folder=to_folder,
            chunk_size=page_size,
        )
        self._cache = None  # Invalidate the cache after delete, regardless of the results
        return res

    def archive(self, to_folder, page_size=1000):
        &#34;&#34;&#34;Archive the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
        to fetch and move per request. We&#39;re only fetching the IDs, so keep it high

        Args:
          to_folder:
          page_size:  (Default value = 1000)

        &#34;&#34;&#34;
        if self.is_cached:
            ids = self._cache
        else:
            ids = self._id_only_copy_self()
            ids.page_size = page_size
        res = self.folder_collection.account.bulk_archive(
            ids=ids,
            to_folder=to_folder,
            chunk_size=page_size,
        )
        self._cache = None  # Invalidate the cache after delete, regardless of the results
        return res

    def __str__(self):
        fmt_args = [(&#39;q&#39;, str(self.q)), (&#39;folders&#39;, &#39;[%s]&#39; % &#39;, &#39;.join(str(f) for f in self.folder_collection.folders))]
        if self.is_cached:
            fmt_args.append((&#39;len&#39;, str(len(self._cache))))
        return self.__class__.__name__ + &#39;(%s)&#39; % &#39;, &#39;.join(&#39;%s=%s&#39; % (k, v) for k, v in fmt_args)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="exchangelib.queryset.SearchableMixIn" href="#exchangelib.queryset.SearchableMixIn">SearchableMixIn</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="exchangelib.queryset.QuerySet.FLAT"><code class="name">var <span class="ident">FLAT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="exchangelib.queryset.QuerySet.ITEM"><code class="name">var <span class="ident">ITEM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="exchangelib.queryset.QuerySet.NONE"><code class="name">var <span class="ident">NONE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="exchangelib.queryset.QuerySet.PERSONA"><code class="name">var <span class="ident">PERSONA</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="exchangelib.queryset.QuerySet.REQUEST_TYPES"><code class="name">var <span class="ident">REQUEST_TYPES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="exchangelib.queryset.QuerySet.RETURN_TYPES"><code class="name">var <span class="ident">RETURN_TYPES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="exchangelib.queryset.QuerySet.VALUES"><code class="name">var <span class="ident">VALUES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="exchangelib.queryset.QuerySet.VALUES_LIST"><code class="name">var <span class="ident">VALUES_LIST</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="exchangelib.queryset.QuerySet.is_cached"><code class="name">var <span class="ident">is_cached</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def is_cached(self):
    return self._cache is not None</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="exchangelib.queryset.QuerySet.all"><code class="name flex">
<span>def <span class="ident">all</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def all(self):
    &#34;&#34;&#34; &#34;&#34;&#34;
    new_qs = self._copy_self()
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.archive"><code class="name flex">
<span>def <span class="ident">archive</span></span>(<span>self, to_folder, page_size=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Archive the items matching the query, with as little effort as possible. 'page_size' is the number of items
to fetch and move per request. We're only fetching the IDs, so keep it high</p>
<h2 id="args">Args</h2>
<dl>
<dt>to_folder:</dt>
<dt><strong><code>page_size</code></strong></dt>
<dd>(Default value = 1000)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def archive(self, to_folder, page_size=1000):
    &#34;&#34;&#34;Archive the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
    to fetch and move per request. We&#39;re only fetching the IDs, so keep it high

    Args:
      to_folder:
      page_size:  (Default value = 1000)

    &#34;&#34;&#34;
    if self.is_cached:
        ids = self._cache
    else:
        ids = self._id_only_copy_self()
        ids.page_size = page_size
    res = self.folder_collection.account.bulk_archive(
        ids=ids,
        to_folder=to_folder,
        chunk_size=page_size,
    )
    self._cache = None  # Invalidate the cache after delete, regardless of the results
    return res</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self, to_folder, page_size=1000, **copy_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Copy the items matching the query, with as little effort as possible. 'page_size' is the number of items
to fetch and copy per request. We're only fetching the IDs, so keep it high</p>
<h2 id="args">Args</h2>
<dl>
<dt>to_folder:</dt>
<dt><strong><code>page_size</code></strong></dt>
<dd>(Default value = 1000)</dd>
</dl>
<p>**copy_kwargs:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self, to_folder, page_size=1000, **copy_kwargs):
    &#34;&#34;&#34;Copy the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
    to fetch and copy per request. We&#39;re only fetching the IDs, so keep it high

    Args:
      to_folder:
      page_size:  (Default value = 1000)
      **copy_kwargs:

    &#34;&#34;&#34;
    if self.is_cached:
        ids = self._cache
    else:
        ids = self._id_only_copy_self()
        ids.page_size = page_size
    res = self.folder_collection.account.bulk_copy(
        ids=ids,
        to_folder=to_folder,
        chunk_size=page_size,
        **copy_kwargs
    )
    self._cache = None  # Invalidate the cache, regardless of the results
    return res</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.count"><code class="name flex">
<span>def <span class="ident">count</span></span>(<span>self, page_size=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the query count, with as little effort as possible 'page_size' is the number of items to
fetch from the server per request. We're only fetching the IDs, so keep it high</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>page_size</code></strong></dt>
<dd>(Default value = 1000)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count(self, page_size=1000):
    &#34;&#34;&#34;Get the query count, with as little effort as possible &#39;page_size&#39; is the number of items to
    fetch from the server per request. We&#39;re only fetching the IDs, so keep it high

    Args:
      page_size:  (Default value = 1000)

    &#34;&#34;&#34;
    if self.is_cached:
        return len(self._cache)
    new_qs = self._copy_self()
    new_qs.only_fields = tuple()
    new_qs.order_fields = None
    new_qs.return_format = self.NONE
    new_qs.page_size = page_size
    return len(list(new_qs.__iter__()))</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.delete"><code class="name flex">
<span>def <span class="ident">delete</span></span>(<span>self, page_size=1000, **delete_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Delete the items matching the query, with as little effort as possible. 'page_size' is the number of items
to fetch and delete per request. We're only fetching the IDs, so keep it high</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>page_size</code></strong></dt>
<dd>(Default value = 1000)</dd>
</dl>
<p>**delete_kwargs:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete(self, page_size=1000, **delete_kwargs):
    &#34;&#34;&#34;Delete the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
    to fetch and delete per request. We&#39;re only fetching the IDs, so keep it high

    Args:
      page_size:  (Default value = 1000)
      **delete_kwargs:

    &#34;&#34;&#34;
    if self.is_cached:
        ids = self._cache
    else:
        ids = self._id_only_copy_self()
        ids.page_size = page_size
    res = self.folder_collection.account.bulk_delete(
        ids=ids,
        chunk_size=page_size,
        **delete_kwargs
    )
    self._cache = None  # Invalidate the cache, regardless of the results
    return res</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.depth"><code class="name flex">
<span>def <span class="ident">depth</span></span>(<span>self, depth)</span>
</code></dt>
<dd>
<div class="desc"><p>Specify the search depth (SHALLOW, ASSOCIATED or DEEP)</p>
<h2 id="args">Args</h2>
<p>depth:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def depth(self, depth):
    &#34;&#34;&#34;Specify the search depth (SHALLOW, ASSOCIATED or DEEP)

    Args:
      depth:

    &#34;&#34;&#34;
    new_qs = self._copy_self()
    new_qs._depth = depth
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.exclude"><code class="name flex">
<span>def <span class="ident">exclude</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p><em>args:
</em>*kwargs:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exclude(self, *args, **kwargs):
    &#34;&#34;&#34;

    Args:
      *args:
      **kwargs:


    &#34;&#34;&#34;
    new_qs = self._copy_self()
    q = ~Q(*args, **kwargs)
    new_qs.q = new_qs.q &amp; q
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.exists"><code class="name flex">
<span>def <span class="ident">exists</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Find out if the query contains any hits, with as little effort as possible</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exists(self):
    &#34;&#34;&#34;Find out if the query contains any hits, with as little effort as possible&#34;&#34;&#34;
    if self.is_cached:
        return len(self._cache) &gt; 0
    new_qs = self._copy_self()
    new_qs.max_items = 1
    return new_qs.count(page_size=1) &gt; 0</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p><em>args:
</em>*kwargs:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, *args, **kwargs):
    &#34;&#34;&#34;

    Args:
      *args:
      **kwargs:


    &#34;&#34;&#34;
    new_qs = self._copy_self()
    q = Q(*args, **kwargs)
    new_qs.q = new_qs.q &amp; q
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Assume the query will return exactly one item. Return that item</p>
<h2 id="args">Args</h2>
<p><em>args:
</em>*kwargs:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self, *args, **kwargs):
    &#34;&#34;&#34;Assume the query will return exactly one item. Return that item

    Args:
      *args:
      **kwargs:

    &#34;&#34;&#34;
    if self.is_cached and not args and not kwargs:
        # We can only safely use the cache if get() is called without args
        items = self._cache
    elif not args and set(kwargs.keys()) in ({&#39;id&#39;}, {&#39;id&#39;, &#39;changekey&#39;}):
        # We allow calling get(id=..., changekey=...) to get a single item, but only if exactly these two
        # kwargs are present.
        account = self.folder_collection.account
        item_id = self._id_field.field.clean(kwargs[&#39;id&#39;], version=account.version)
        changekey = self._changekey_field.field.clean(kwargs.get(&#39;changekey&#39;), version=account.version)
        items = list(account.fetch(ids=[(item_id, changekey)], only_fields=self.only_fields))
    else:
        new_qs = self.filter(*args, **kwargs)
        items = list(new_qs.__iter__())
    if not items:
        raise DoesNotExist()
    if len(items) != 1:
        raise MultipleObjectsReturned()
    return items[0]</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.iterator"><code class="name flex">
<span>def <span class="ident">iterator</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iterator(self):
    &#34;&#34;&#34; &#34;&#34;&#34;
    if self.q.is_never():
        return []
    if self.is_cached:
        return self._cache
    # Return an iterator that doesn&#39;t bother with caching
    return self._format_items(items=self._query(), return_format=self.return_format)</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.move"><code class="name flex">
<span>def <span class="ident">move</span></span>(<span>self, to_folder, page_size=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Move the items matching the query, with as little effort as possible. 'page_size' is the number of items
to fetch and move per request. We're only fetching the IDs, so keep it high</p>
<h2 id="args">Args</h2>
<dl>
<dt>to_folder:</dt>
<dt><strong><code>page_size</code></strong></dt>
<dd>(Default value = 1000)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def move(self, to_folder, page_size=1000):
    &#34;&#34;&#34;Move the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
    to fetch and move per request. We&#39;re only fetching the IDs, so keep it high

    Args:
      to_folder:
      page_size:  (Default value = 1000)

    &#34;&#34;&#34;
    if self.is_cached:
        ids = self._cache
    else:
        ids = self._id_only_copy_self()
        ids.page_size = page_size
    res = self.folder_collection.account.bulk_move(
        ids=ids,
        to_folder=to_folder,
        chunk_size=page_size,
    )
    self._cache = None  # Invalidate the cache after delete, regardless of the results
    return res</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.none"><code class="name flex">
<span>def <span class="ident">none</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def none(self):
    &#34;&#34;&#34; &#34;&#34;&#34;
    new_qs = self._copy_self()
    new_qs.q = Q(conn_type=Q.NEVER)
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.only"><code class="name flex">
<span>def <span class="ident">only</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Fetch only the specified field names. All other item fields will be 'None'</p>
<h2 id="args">Args</h2>
<p>*args:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def only(self, *args):
    &#34;&#34;&#34;Fetch only the specified field names. All other item fields will be &#39;None&#39;

    Args:
      *args:

    &#34;&#34;&#34;
    try:
        only_fields = tuple(self._get_field_path(arg) for arg in args)
    except ValueError as e:
        raise ValueError(&#34;%s in only()&#34; % e.args[0])
    new_qs = self._copy_self()
    new_qs.only_fields = only_fields
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.order_by"><code class="name flex">
<span>def <span class="ident">order_by</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>*args:</p>
<h2 id="returns">Returns</h2>
<p>in reverse order. EWS only supports server-side sorting on a single field. Sorting on multiple fields is
implemented client-side and will therefore make the query greedy</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def order_by(self, *args):
    &#34;&#34;&#34;

    Args:
      *args:

    Returns:
      in reverse order. EWS only supports server-side sorting on a single field. Sorting on multiple fields is
      implemented client-side and will therefore make the query greedy

    &#34;&#34;&#34;
    try:
        order_fields = tuple(self._get_field_order(arg) for arg in args)
    except ValueError as e:
        raise ValueError(&#34;%s in order_by()&#34; % e.args[0])
    new_qs = self._copy_self()
    new_qs.order_fields = order_fields
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.people"><code class="name flex">
<span>def <span class="ident">people</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Changes the queryset to search the folder for Personas instead of Items</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def people(self):
    &#34;&#34;&#34;Changes the queryset to search the folder for Personas instead of Items&#34;&#34;&#34;
    new_qs = self._copy_self()
    new_qs.request_type = self.PERSONA
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.reverse"><code class="name flex">
<span>def <span class="ident">reverse</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reverse(self):
    &#34;&#34;&#34; &#34;&#34;&#34;
    if not self.order_fields:
        raise ValueError(&#39;Reversing only makes sense if there are order_by fields&#39;)
    new_qs = self._copy_self()
    for f in new_qs.order_fields:
        f.reverse = not f.reverse
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.send"><code class="name flex">
<span>def <span class="ident">send</span></span>(<span>self, page_size=1000, **send_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Send the items matching the query, with as little effort as possible. 'page_size' is the number of items
to fetch and send per request. We're only fetching the IDs, so keep it high</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>page_size</code></strong></dt>
<dd>(Default value = 1000)</dd>
</dl>
<p>**send_kwargs:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send(self, page_size=1000, **send_kwargs):
    &#34;&#34;&#34;Send the items matching the query, with as little effort as possible. &#39;page_size&#39; is the number of items
    to fetch and send per request. We&#39;re only fetching the IDs, so keep it high

    Args:
      page_size:  (Default value = 1000)
      **send_kwargs:

    &#34;&#34;&#34;
    if self.is_cached:
        ids = self._cache
    else:
        ids = self._id_only_copy_self()
        ids.page_size = page_size
    res = self.folder_collection.account.bulk_send(
        ids=ids,
        chunk_size=page_size,
        **send_kwargs
    )
    self._cache = None  # Invalidate the cache, regardless of the results
    return res</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.values"><code class="name flex">
<span>def <span class="ident">values</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>*args:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def values(self, *args):
    &#34;&#34;&#34;

    Args:
      *args:


    &#34;&#34;&#34;
    try:
        only_fields = tuple(self._get_field_path(arg) for arg in args)
    except ValueError as e:
        raise ValueError(&#34;%s in values()&#34; % e.args[0])
    new_qs = self._copy_self()
    new_qs.only_fields = only_fields
    new_qs.return_format = self.VALUES
    return new_qs</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.QuerySet.values_list"><code class="name flex">
<span>def <span class="ident">values_list</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the values of the specified field names as lists. If called with flat=True and only one field name,</p>
<h2 id="args">Args</h2>
<p><em>args:
</em>*kwargs:</p>
<h2 id="returns">Returns</h2>
<p>Allow an arbitrary list of fields in *args, possibly ending with flat=True|False</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def values_list(self, *args, **kwargs):
    &#34;&#34;&#34;Return the values of the specified field names as lists. If called with flat=True and only one field name,

    Args:
      *args:
      **kwargs:

    Returns:
      Allow an arbitrary list of fields in *args, possibly ending with flat=True|False

    &#34;&#34;&#34;
    flat = kwargs.pop(&#39;flat&#39;, False)
    if kwargs:
        raise AttributeError(&#39;Unknown kwargs: %s&#39; % kwargs)
    if flat and len(args) != 1:
        raise ValueError(&#39;flat=True requires exactly one field name&#39;)
    try:
        only_fields = tuple(self._get_field_path(arg) for arg in args)
    except ValueError as e:
        raise ValueError(&#34;%s in values_list()&#34; % e.args[0])
    new_qs = self._copy_self()
    new_qs.only_fields = only_fields
    new_qs.return_format = self.FLAT if flat else self.VALUES_LIST
    return new_qs</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="exchangelib.queryset.SearchableMixIn"><code class="flex name class">
<span>class <span class="ident">SearchableMixIn</span></span>
</code></dt>
<dd>
<div class="desc"><p>Implements a search API for inheritance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SearchableMixIn:
    &#34;&#34;&#34;Implements a search API for inheritance&#34;&#34;&#34;

    def get(self, *args, **kwargs):
        raise NotImplementedError()

    def all(self):
        raise NotImplementedError()

    def none(self):
        raise NotImplementedError()

    def filter(self, *args, **kwargs):
        raise NotImplementedError()

    def exclude(self, *args, **kwargs):
        raise NotImplementedError()

    def people(self):
        raise NotImplementedError()</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="exchangelib.folders.base.BaseFolder" href="folders/base.html#exchangelib.folders.base.BaseFolder">BaseFolder</a></li>
<li><a title="exchangelib.folders.collections.FolderCollection" href="folders/collections.html#exchangelib.folders.collections.FolderCollection">FolderCollection</a></li>
<li><a title="exchangelib.queryset.QuerySet" href="#exchangelib.queryset.QuerySet">QuerySet</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="exchangelib.queryset.SearchableMixIn.all"><code class="name flex">
<span>def <span class="ident">all</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def all(self):
    raise NotImplementedError()</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.SearchableMixIn.exclude"><code class="name flex">
<span>def <span class="ident">exclude</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exclude(self, *args, **kwargs):
    raise NotImplementedError()</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.SearchableMixIn.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, *args, **kwargs):
    raise NotImplementedError()</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.SearchableMixIn.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self, *args, **kwargs):
    raise NotImplementedError()</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.SearchableMixIn.none"><code class="name flex">
<span>def <span class="ident">none</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def none(self):
    raise NotImplementedError()</code></pre>
</details>
</dd>
<dt id="exchangelib.queryset.SearchableMixIn.people"><code class="name flex">
<span>def <span class="ident">people</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def people(self):
    raise NotImplementedError()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="exchangelib" href="index.html">exchangelib</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="exchangelib.queryset.QuerySet" href="#exchangelib.queryset.QuerySet">QuerySet</a></code></h4>
<ul class="two-column">
<li><code><a title="exchangelib.queryset.QuerySet.FLAT" href="#exchangelib.queryset.QuerySet.FLAT">FLAT</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.ITEM" href="#exchangelib.queryset.QuerySet.ITEM">ITEM</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.NONE" href="#exchangelib.queryset.QuerySet.NONE">NONE</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.PERSONA" href="#exchangelib.queryset.QuerySet.PERSONA">PERSONA</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.REQUEST_TYPES" href="#exchangelib.queryset.QuerySet.REQUEST_TYPES">REQUEST_TYPES</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.RETURN_TYPES" href="#exchangelib.queryset.QuerySet.RETURN_TYPES">RETURN_TYPES</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.VALUES" href="#exchangelib.queryset.QuerySet.VALUES">VALUES</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.VALUES_LIST" href="#exchangelib.queryset.QuerySet.VALUES_LIST">VALUES_LIST</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.all" href="#exchangelib.queryset.QuerySet.all">all</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.archive" href="#exchangelib.queryset.QuerySet.archive">archive</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.copy" href="#exchangelib.queryset.QuerySet.copy">copy</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.count" href="#exchangelib.queryset.QuerySet.count">count</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.delete" href="#exchangelib.queryset.QuerySet.delete">delete</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.depth" href="#exchangelib.queryset.QuerySet.depth">depth</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.exclude" href="#exchangelib.queryset.QuerySet.exclude">exclude</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.exists" href="#exchangelib.queryset.QuerySet.exists">exists</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.filter" href="#exchangelib.queryset.QuerySet.filter">filter</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.get" href="#exchangelib.queryset.QuerySet.get">get</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.is_cached" href="#exchangelib.queryset.QuerySet.is_cached">is_cached</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.iterator" href="#exchangelib.queryset.QuerySet.iterator">iterator</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.move" href="#exchangelib.queryset.QuerySet.move">move</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.none" href="#exchangelib.queryset.QuerySet.none">none</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.only" href="#exchangelib.queryset.QuerySet.only">only</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.order_by" href="#exchangelib.queryset.QuerySet.order_by">order_by</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.people" href="#exchangelib.queryset.QuerySet.people">people</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.reverse" href="#exchangelib.queryset.QuerySet.reverse">reverse</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.send" href="#exchangelib.queryset.QuerySet.send">send</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.values" href="#exchangelib.queryset.QuerySet.values">values</a></code></li>
<li><code><a title="exchangelib.queryset.QuerySet.values_list" href="#exchangelib.queryset.QuerySet.values_list">values_list</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="exchangelib.queryset.SearchableMixIn" href="#exchangelib.queryset.SearchableMixIn">SearchableMixIn</a></code></h4>
<ul class="two-column">
<li><code><a title="exchangelib.queryset.SearchableMixIn.all" href="#exchangelib.queryset.SearchableMixIn.all">all</a></code></li>
<li><code><a title="exchangelib.queryset.SearchableMixIn.exclude" href="#exchangelib.queryset.SearchableMixIn.exclude">exclude</a></code></li>
<li><code><a title="exchangelib.queryset.SearchableMixIn.filter" href="#exchangelib.queryset.SearchableMixIn.filter">filter</a></code></li>
<li><code><a title="exchangelib.queryset.SearchableMixIn.get" href="#exchangelib.queryset.SearchableMixIn.get">get</a></code></li>
<li><code><a title="exchangelib.queryset.SearchableMixIn.none" href="#exchangelib.queryset.SearchableMixIn.none">none</a></code></li>
<li><code><a title="exchangelib.queryset.SearchableMixIn.people" href="#exchangelib.queryset.SearchableMixIn.people">people</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.3</a>.</p>
</footer>
</body>
</html>